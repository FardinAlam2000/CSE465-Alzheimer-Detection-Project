{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a106ef34-faae-4a28-bf29-92feaa2ff4ca",
   "metadata": {},
   "source": [
    "**An Efficient Ensemble Approach for Alzheimerâ€™s Disease\n",
    "Detection Using an Adaptive Synthetic Technique and\n",
    "Deep Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50925b9d-d3fc-49a2-b96d-866014c3b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629249a4-23eb-44ac-81a3-02b1f3f5873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available. Using CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"GPU is available. Using {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available. Using CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c122c46-1f2e-4d38-a364-20b62efd10b3",
   "metadata": {},
   "source": [
    "<h1>Preprocessing the Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf9ae1c-fc28-4d68-a1b5-063372c7407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_directory = r'C:\\Users\\alamm\\Downloads\\Alzheimer Disease\\archive (13)\\Alzheimer_MRI_4_classes_dataset'\n",
    "classes = os.listdir(dataset_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dbad8d3-846e-4d27-92fa-33409c1185b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in class 'MildDemented': 896\n",
      "Number of files in class 'ModerateDemented': 64\n",
      "Number of files in class 'NonDemented': 3200\n",
      "Number of files in class 'VeryMildDemented': 2240\n",
      "Total instances of images: 6400\n"
     ]
    }
   ],
   "source": [
    "total_images = 0\n",
    "for class_name in classes:\n",
    "    class_directory = os.path.join(dataset_directory, class_name)\n",
    "    if os.path.isdir(class_directory):\n",
    "        files = os.listdir(class_directory)\n",
    "        num_files = len(files)\n",
    "        print(f\"Number of files in class '{class_name}': {num_files}\")\n",
    "        total_images += num_files\n",
    "\n",
    "print(f\"Total instances of images: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d800c4-7534-4abe-a94a-4ad830483c4b",
   "metadata": {},
   "source": [
    "<h3>Balancing the dataset through ADASYN oversampling method</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "229bcde7-092f-4480-8d45-80b2ec4b4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import datasets, transforms\n",
    "dataset = datasets.ImageFolder(root=dataset_directory)\n",
    "\n",
    "X = [img for img, label in dataset]\n",
    "y = [label for img, label in dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4cfc5e-cdad-4e78-851f-696b9601f066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from PIL import Image\n",
    "\n",
    "def apply_adasyn(X, y):\n",
    "    X_arrays = [np.array(img) for img in X]\n",
    "    \n",
    "    img_shape = X_arrays[0].shape\n",
    "    \n",
    "    X_reshaped = np.array([x.flatten() for x in X_arrays])\n",
    "    \n",
    "    adasyn = ADASYN(random_state=42)\n",
    "    \n",
    "    X_resampled, y_resampled = adasyn.fit_resample(X_reshaped, y)\n",
    "\n",
    "    X_balanced = [x.reshape(img_shape) for x in X_resampled]\n",
    "    \n",
    "    X_balanced = [Image.fromarray(x.astype('uint8')) for x in X_balanced]\n",
    "    \n",
    "    return X_balanced, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3af0c7d8-bf47-43e1-89f2-fcab4255ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_balanced, y_balanced = apply_adasyn(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c6ad03-8f07-4f87-9470-0ab5acdf67c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12805"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97bde3b4-205c-4094-b491-75f652152eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12805"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f583c6-bf5a-4b84-9a90-a177f61a5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7138319-5158-4645-89ce-aae511dbd1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 8963\n",
      "Validation set size: 1281\n",
      "Test set size: 2561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, stratify=y_train, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4eaec48-2f8f-42a8-82eb-c3e2fc44ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5c70856-3bd1-4898-a93b-bfa845e624be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6e98eaf-097a-4a61-8955-db216e215bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_early_stopping(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device='cuda'):\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                break\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318979ce-181b-4d51-9e37-5ea9179c41e2",
   "metadata": {},
   "source": [
    "<h1>DenseNet121</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b5083f1-4489-4c40-9bb6-72f3680577c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = timm.create_model(\"densenet121\", pretrained=True, num_classes=4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ea1a8-5328-4ebe-9377-c53993f935dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 - Loss: 1.1249 - Accuracy: 0.5234\n",
      "Epoch 2/4 - Loss: 0.9588 - Accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "# Loss, optimizer, scheduler setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "# Dataset loading\n",
    "full_dataset = datasets.ImageFolder(root=dataset_directory, transform=transform)\n",
    "\n",
    "# 80/20 split\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ---- Manual Training on 1/10 of Train Set ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "max_batches = len(train_loader) // 10\n",
    "num_epochs = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        if i >= max_batches:\n",
    "            break\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total_samples += inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = running_corrects.double() / total_samples\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    # Step scheduler (optional)\n",
    "    scheduler.step(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e00cb-2341-46fe-a93a-21473d28392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, num_classes, device='cuda'):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)  \n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(outputs.softmax(dim=1).cpu().numpy())  \n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "\n",
    "    report = classification_report(all_labels, all_preds,digits=4, target_names=[f'Class {i}' for i in range(num_classes)])\n",
    "    \n",
    "    if num_classes > 2:\n",
    "        auc_score = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n",
    "    else:\n",
    "        auc_score = roc_auc_score(all_labels, [prob[1] for prob in all_probs])\n",
    "\n",
    "    return test_acc, report, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e75aee-1225-491a-859c-e689f9e1aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = val_loader\n",
    "\n",
    "test_accuracy, classification_report_str, auc_score = test_model(model, test_loader, num_classes=4, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3b2da-6b6e-48db-b1e4-01a13b6d17c2",
   "metadata": {},
   "source": [
    "<h1>Xception</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383c537-af5b-4842-a1ff-4bc7d5ee4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = timm.create_model(\"xception\", pretrained=True, num_classes=4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c1266-9f0f-4de3-82f3-bbd614c20400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_early_stopping(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, device, patience=5, batch_fraction=1.0):\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        max_batches = int(len(train_loader) * batch_fraction)\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            if i >= max_batches:\n",
    "                break\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Train Loss: {running_loss / max_batches:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=3,\n",
    "    device=device,\n",
    "    batch_fraction=0.1  # <-- This trains on only 1/10th of batches\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd926d7-71c7-4de6-9de3-206208f2aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = val_loader\n",
    "\n",
    "test_accuracy, classification_report_str, auc_score = test_model(model, test_loader, num_classes=4, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054691c0-a8eb-491b-85ce-7cb06121a33c",
   "metadata": {},
   "source": [
    "<h1>EfficientNetB2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86141a-0cff-4177-9a65-6f4616718cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = timm.create_model(\"efficientnet_b2\", pretrained=True, num_classes=4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057f3e0-b892-43d8-b4a9-a3366edeb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_early_stopping(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, device, patience=5, batch_fraction=1.0):\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        max_batches = int(len(train_loader) * batch_fraction)\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            if i >= max_batches:\n",
    "                break\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Train Loss: {running_loss / max_batches:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=3,\n",
    "    device=device,\n",
    "    batch_fraction=0.1  # <-- This trains on only 1/10th of batches\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e13911-cb9c-40be-ae02-1a6a2cf20714",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = val_loader\n",
    "\n",
    "test_accuracy, classification_report_str, auc_score = test_model(model, test_loader, num_classes=4, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aa2127-82cf-4be2-b3a8-fdb0e61565ca",
   "metadata": {},
   "source": [
    "<h1>VGG16</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c16707-a99c-4b82-8fe0-2af8b9cb3b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(in_features=model.classifier[6].in_features, out_features=4)    \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8684d4b9-0be2-4cef-9af7-cb0aac9b788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_early_stopping(model, train_loader, val_loader, optimizer, criterion, scheduler, num_epochs, device, patience=5, batch_fraction=1.0):\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        max_batches = int(len(train_loader) * batch_fraction)\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            if i >= max_batches:\n",
    "                break\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        print(f\"Train Loss: {running_loss / max_batches:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=3,\n",
    "    device=device,\n",
    "    batch_fraction=0.1  # <-- This trains on only 1/10th of batches\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9c790-2dd6-4086-ae50-766328e9970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = val_loader\n",
    "\n",
    "test_accuracy, classification_report_str, auc_score = test_model(model, test_loader, num_classes=4, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e9089-d18f-49ab-9dc0-5790d709d50a",
   "metadata": {},
   "source": [
    "<h1>CNN</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c6f11-5f82-45b9-903c-8914cba5173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 128)  # Corrected input size\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # First conv block\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        # Second conv block\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        # Third conv block\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Softmax output\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CustomCNN(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783275ad-0c17-4b16-9176-d63e6794ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=50,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a33c1-34b8-48ca-bf1a-425c2d4ba9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = val_loader\n",
    "\n",
    "test_accuracy, classification_report_str, auc_score = test_model(model, test_loader, num_classes=4, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a4ea68-cd76-477f-a23e-f6642852b6a3",
   "metadata": {},
   "source": [
    "<h1>EfficientNet-B2+VGG16 Ensemble</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a66f2a-8d7b-448c-9570-ed222a8b2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "from torchvision import models\n",
    "model = timm.create_model(\"efficientnet_b2\", pretrained=True)\n",
    "model.classifier = nn.Identity()\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224),  \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b3b84-fbe1-4372-bed4-798c2439b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier = nn.Identity()\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224),  \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd2267-5548-4304-a791-a362710b8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        \n",
    "        # VGG16 model without classifier\n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        self.vgg16.classifier = nn.Identity() \n",
    "        \n",
    "        # EfficientNet-B2 model without classifier\n",
    "        self.efficientnet = timm.create_model(\"efficientnet_b2\", pretrained=True)\n",
    "        self.efficientnet.classifier = nn.Identity()  # Remove the classifier\n",
    "        \n",
    "        # Adaptive pooling to match the output sizes\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn1 = nn.BatchNorm1d(7 * 7 * (512 + 1408))  # Concatenating VGG16 (512) + EfficientNet-B2 (1408)\n",
    "        self.fc1 = nn.Linear(7 * 7 * (512 + 1408), 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # VGG16 feature extraction\n",
    "        vgg_features = self.vgg16.features(x)  # Extract features using VGG16\n",
    "        vgg_features = self.adaptive_pool(vgg_features)\n",
    "        \n",
    "        # EfficientNet-B2 feature extraction\n",
    "        efficientnet_features = self.efficientnet.forward_features(x)  # Extract features using EfficientNet-B2\n",
    "        efficientnet_features = self.adaptive_pool(efficientnet_features)\n",
    "        \n",
    "        # Concatenate features along the channel dimension\n",
    "        combined_features = torch.cat((vgg_features, efficientnet_features), dim=1)\n",
    "        \n",
    "        # Process combined features\n",
    "        x = self.dropout1(combined_features)\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def create_model(num_classes=4):\n",
    "    return EnsembleModel(num_classes)\n",
    "\n",
    "model = create_model(num_classes=4).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52196bb9-1052-46ca-a895-aa00e827ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=5,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b2333-1b27-4f76-80fd-f4a7ef22c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, num_classes, device='cuda'):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)  \n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(outputs.softmax(dim=1).cpu().numpy())  \n",
    "\n",
    "    test_acc = test_correct / test_total\n",
    "    class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "\n",
    "    report = classification_report(all_labels, all_preds,digits=4, target_names= class_names)\n",
    "    \n",
    "    \n",
    "    if num_classes > 2:\n",
    "        auc_score = roc_auc_score(all_labels, all_probs, multi_class='ovr')\n",
    "    else:\n",
    "        auc_score = roc_auc_score(all_labels, [prob[1] for prob in all_probs])\n",
    "\n",
    "    return test_acc, report, auc_score, all_labels, all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e76fa5-57f2-4360-b632-fd20b289aa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, classification_report_str, auc_score, true_labels, predictions = test_model(model, test_loader, num_classes=4, device='cuda')\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt=\".0f\", xticklabels = class_names, yticklabels = class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234adf19-3b3c-4ec0-a74b-47bdcc7492d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53066d-6738-4d72-83db-7ca81434fa71",
   "metadata": {},
   "source": [
    "<h1>EfficientNet-B2+DenseNet-121 Ensemble</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf7641-1507-4860-afec-6e71ef86a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "import timm\n",
    "from torchvision import models\n",
    "model = timm.create_model(\"densenet121\", pretrained=True)\n",
    "model.classifier = nn.Identity()\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224),  \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f043dd5-de1f-453a-aa2d-911ce6521b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        \n",
    "        self.densenet = timm.create_model(\"densenet121\", pretrained=True)\n",
    "        self.densenet.classifier = nn.Identity() \n",
    "        \n",
    "        # EfficientNet-B2 model without classifier\n",
    "        self.efficientnet = timm.create_model(\"efficientnet_b2\", pretrained=True)\n",
    "        self.efficientnet.classifier = nn.Identity()  # Remove the classifier\n",
    "        \n",
    "        # Adaptive pooling to match the output sizes\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn1 = nn.BatchNorm1d(7 * 7 * (1024 + 1408))  # Concatenating VGG16 (512) + EfficientNet-B2 (1408)\n",
    "        self.fc1 = nn.Linear(7 * 7 * (1024 + 1408), 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        densenet_features = self.densenet.forward_features(x)  # Extract features using VGG16\n",
    "        densenet_features = self.adaptive_pool(densenet_features)\n",
    "        \n",
    "        efficientnet_features = self.efficientnet.forward_features(x)  # Extract features using EfficientNet-B2\n",
    "        efficientnet_features = self.adaptive_pool(efficientnet_features)\n",
    "        \n",
    "        # Concatenate features along the channel dimension\n",
    "        combined_features = torch.cat((densenet_features, efficientnet_features), dim=1)\n",
    "        \n",
    "        # Process combined features\n",
    "        x = self.dropout1(combined_features)\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def create_model(num_classes=4):\n",
    "    return EnsembleModel(num_classes)\n",
    "\n",
    "model = create_model(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac563f3-fb8d-4e9c-b8b5-e50dcf742d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=5,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2ceb2-5ac3-486c-8a7c-ebdd4ad8118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, classification_report_str, auc_score, true_labels, predictions = test_model(model, test_loader, num_classes=4, device='cuda')\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt=\".0f\", xticklabels = class_names, yticklabels = class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e0e96-4e88-47d2-b089-437b4c242b37",
   "metadata": {},
   "source": [
    "<h1>EfficientNet-B2+Xception</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1043299-90fd-4a74-8014-d197acb92ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "import timm\n",
    "from torchvision import models\n",
    "model = timm.create_model(\"xception\", pretrained=True)\n",
    "model.fc = nn.Identity()\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224),  \n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab5cc34-29c1-4731-95c5-5978ca902a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        \n",
    "        self.xception = timm.create_model(\"xception\", pretrained=True)\n",
    "        self.xception.fc = nn.Identity() \n",
    "        \n",
    "        self.efficientnet = timm.create_model(\"efficientnet_b2\", pretrained=True)\n",
    "        self.efficientnet.classifier = nn.Identity()  # Remove the classifier\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn1 = nn.BatchNorm1d(7 * 7 * (2048 + 1408))  \n",
    "        self.fc1 = nn.Linear(7 * 7 * (2048 + 1408), 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        xception_features = self.xception.forward_features(x)  \n",
    "        xception_features = self.adaptive_pool(xception_features)\n",
    "        \n",
    "        efficientnet_features = self.efficientnet.forward_features(x)  \n",
    "        efficientnet_features = self.adaptive_pool(efficientnet_features)\n",
    "        \n",
    "        combined_features = torch.cat((xception_features, efficientnet_features), dim=1)\n",
    "        \n",
    "        x = self.dropout1(combined_features)\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def create_model(num_classes=4):\n",
    "    return EnsembleModel(num_classes)\n",
    "\n",
    "model = create_model(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f7096-bbb8-4bab-a966-6afae2ef862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=50,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980f0f2-e160-4544-8fc8-c7f1c6a03bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, classification_report_str, auc_score, true_labels, predictions = test_model(model, test_loader, num_classes=4, device='cuda')\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt=\".0f\", xticklabels = class_names, yticklabels = class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e6db9-7e5f-41b7-a78d-82d53238d675",
   "metadata": {},
   "source": [
    "<h1>VGG16+DenseNet-121</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322dd14d-b397-40e4-8c54-9231dcab949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        \n",
    "        self.vgg16 = models.vgg16(pretrained=True)\n",
    "        self.vgg16.classifier = nn.Identity() \n",
    "        \n",
    "        self.densenet = timm.create_model(\"densenet121\", pretrained=True)\n",
    "        self.densenet.classifier = nn.Identity() \n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn1 = nn.BatchNorm1d(7 * 7 * (512 + 1024))  \n",
    "        self.fc1 = nn.Linear(7 * 7 * (512 + 1024), 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # VGG16 feature extraction\n",
    "        vgg_features = self.vgg16.features(x)  \n",
    "        vgg_features = self.adaptive_pool(vgg_features)\n",
    "        \n",
    "        densenet_features = self.densenet.forward_features(x)  \n",
    "        densenet_features = self.adaptive_pool(densenet_features)\n",
    "        \n",
    "        combined_features = torch.cat((vgg_features, densenet_features), dim=1)\n",
    "        \n",
    "        x = self.dropout1(combined_features)\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def create_model(num_classes=4):\n",
    "    return EnsembleModel(num_classes)\n",
    "\n",
    "model = create_model(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bceb3cd-46c2-4232-9110-930ac25d84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=50,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3d46c7-6aff-4c04-b1f8-4c882b7c3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, classification_report_str, auc_score, true_labels, predictions = test_model(model, test_loader, num_classes=4, device='cuda')\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt=\".0f\", xticklabels = class_names, yticklabels = class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c895a90-c0a5-45a7-a1d2-c938cb70e1e7",
   "metadata": {},
   "source": [
    "<h1>Xception+DenseNet-121</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25014904-16f9-421a-8127-ab87ffb6fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision import models\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        \n",
    "        self.xception = timm.create_model(\"xception\", pretrained=True)\n",
    "        self.xception.fc = nn.Identity() \n",
    "        \n",
    "        self.densenet = timm.create_model(\"densenet121\", pretrained=True)\n",
    "        self.densenet.classifier = nn.Identity()\n",
    "        \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.bn1 = nn.BatchNorm1d(7 * 7 * (2048 + 1024))  \n",
    "        self.fc1 = nn.Linear(7 * 7 * (2048 + 1024), 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        xception_features = self.xception.forward_features(x)  \n",
    "        xception_features = self.adaptive_pool(xception_features)\n",
    "        \n",
    "        densenet_features = self.densenet.forward_features(x)  \n",
    "        densenet_features = self.adaptive_pool(densenet_features)\n",
    "        \n",
    "        combined_features = torch.cat((xception_features, densenet_features), dim=1)\n",
    "        \n",
    "        x = self.dropout1(combined_features)\n",
    "        x = self.flatten(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def create_model(num_classes=4):\n",
    "    return EnsembleModel(num_classes)\n",
    "\n",
    "model = create_model(num_classes=4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a1f1a7-7128-42b2-a3eb-ace4da11ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "model = train_model_with_early_stopping(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=50,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd94e7-c52c-4e38-a619-6ffa6aee389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, classification_report_str, auc_score, true_labels, predictions = test_model(model, test_loader, num_classes=4, device='cuda')\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report_str)\n",
    "print(f'AUC Score: {auc_score:.4f}')\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names = ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt=\".0f\", xticklabels = class_names, yticklabels = class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a4d658-8825-475c-a505-0bfc03e5333f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
